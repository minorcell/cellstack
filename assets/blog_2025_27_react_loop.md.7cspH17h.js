import{_ as a,c as t,o as i,a9 as e}from"./chunks/framework.DsVI9alt.js";const g=JSON.parse('{"title":"Agent ReAct and Loop","description":"深入解析 AI Agent 的 ReAct 架构和工作循环原理，探讨智能体如何实现自动化任务执行，从理论到实践的完整指南。","frontmatter":{"title":"Agent ReAct and Loop","description":"深入解析 AI Agent 的 ReAct 架构和工作循环原理，探讨智能体如何实现自动化任务执行，从理论到实践的完整指南。","author":"mcell","tags":["AI Agent","ReAct","Loop","LLM","人工智能","大语言模型","工具调用","智能体架构","自动化","AI工程"],"keywords":["ReAct架构","AI Agent循环","智能体工作原理","LLM工具调用","Agent自动化","思考行动循环","AI推理执行","智能体设计模式","工具执行机制","AI Agent开发"],"head":[["link",{"rel":"canonical","href":"https://stack.mcell.topblog/2025/27_react_loop"}],["meta",{"property":"og:url","content":"https://stack.mcell.topblog/2025/27_react_loop"}]]},"headers":[],"relativePath":"blog/2025/27_react_loop.md","filePath":"blog/2025/27_react_loop.md","lastUpdated":1761937512000}'),l={name:"blog/2025/27_react_loop.md"};function n(o,s,p,h,c,r){return i(),t("div",null,s[0]||(s[0]=[e(`<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/065.png" alt="065.png" loading="lazy"></p><h1 id="agent-react-and-loop" tabindex="-1">Agent ReAct and Loop <a class="header-anchor" href="#agent-react-and-loop" aria-label="Permalink to &quot;Agent ReAct and Loop&quot;">​</a></h1><p>我一直在使用 ChatGPT 或通义千问这样的 AI 工具，它们很强大，但多数情况下都是“一问一答”。我提一个问题，它给一个答案。</p><p>但我注意到，像 Manus 或 Claude Code CLI 这样的“Agent”（智能体）产品，它们似乎可以<strong>自动执行</strong>任务。你给它一个目标，它会自己去调用工具、分析结果、继续下一步，直到任务完成。</p><p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/066.png" alt="066" loading="lazy"></p><p>这到底是怎么做到的？它如何摆脱“一问一答”的限制，实现自动循环？这就是我这周探索的问题。</p><h2 id="关键概念-react" tabindex="-1">关键概念：ReAct <a class="header-anchor" href="#关键概念-react" aria-label="Permalink to &quot;关键概念：ReAct&quot;">​</a></h2><p>我读了一些资料，发现了一个关键概念：<strong>ReAct</strong>。</p><p>这是 2022 年一篇论文（<a href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noreferrer">ReAct: Synergizing Reasoning and Acting in Language Models</a>）提出的思想。它模仿了人类的工作方式：</p><ol><li><strong>Reason（思考）</strong>：分析当前情况，决定下一步该做什么。</li><li><strong>Act（行动）</strong>：执行一个动作（比如调用工具、搜索信息）。</li></ol><p>完成“行动”后，会得到一个新的“观察”（Observation），比如工具的返回结果。然后，Agent 带着这个新结果，回到第 1 步，再次“思考”，形成一个循环。</p><h2 id="一个线索-claude-的日志" tabindex="-1">一个线索：Claude 的日志 <a class="header-anchor" href="#一个线索-claude-的日志" aria-label="Permalink to &quot;一个线索：Claude 的日志&quot;">​</a></h2><p>这个“思考-行动”的循环听起来很合理。为了验证它，我做了一个小实验。</p><p>我查看了 Claude 编码助手（我在 Mac 上的路径是 <code>./claude/projects/*.jsonl</code>）的会话日志文件。这些 <code>.jsonl</code> 文件记录了我和 Agent 的完整对话。</p><p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/067.png" alt="067" loading="lazy"></p><p>我发现，里面的消息（Message）并不仅仅是“我问”和“它答”，而是主要有四种类型：</p><ul><li><code>user</code>：用户的消息。</li><li><code>assistant</code>：模型（Agent）的消息。</li><li><code>tool_call</code>：模型决定调用一个工具。</li><li><code>tool_result</code>：工具执行后返回的结果。</li></ul><p>这揭示了一个秘密：<code>assistant</code> 的回复并不总是最终答案。它可能是一个 <code>tool_call</code>（工具调用）请求，用来告诉外部程序：“请帮我执行这个函数”。</p><p>执行完毕后，系统会把 <code>tool_result</code>（工具结果）再发给 <code>assistant</code>。</p><h2 id="流程-一个循环" tabindex="-1">流程：一个循环 <a class="header-anchor" href="#流程-一个循环" aria-label="Permalink to &quot;流程：一个循环&quot;">​</a></h2><p>看到这里，我基本想通了。Agent 的自动执行，本质上就是这样一个流程：</p><blockquote><p><code>[用户输入]</code> -&gt; <code>[LLM 思考]</code> -&gt; <code>[决定：调用工具 A]</code> -&gt; <code>[系统执行 A]</code> -&gt; <code>[A 的结果]</code> -&gt; <code>[LLM 思考]</code> -&gt; <code>[决定：调用工具 B]</code> -&gt; <code>[系统执行 B]</code> -&gt; ... -&gt; <code>[最终答案]</code></p></blockquote><p>这个流程的核心，就是一个<strong>循环（Loop）</strong>。</p><p>只要 LLM 返回的不是最终答案，而是一个 <code>tool_call</code>，系统就去执行它，然后把结果塞回去，让 LLM 继续“思考”。</p><h2 id="demo-快速验证" tabindex="-1">Demo 快速验证 <a class="header-anchor" href="#demo-快速验证" aria-label="Permalink to &quot;Demo 快速验证&quot;">​</a></h2><p>我的逻辑很清晰：一个主函数，它负责调用 LLM。调用后，检查返回结果。</p><ul><li>如果结果是普通文本（最终答案），就返回它。</li><li>如果结果是 <code>tool_call</code>，就去执行工具，然后把工具结果和之前的对话历史“拼”在一起，<strong>递归调用</strong>自己。</li></ul><p>下面是一个简化的伪代码：</p><div class="language-javascript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> SimpleAgent</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  async</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> chat</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">message</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> assistantResponse</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> this</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">callLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(message)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (assistantResponse.hasToolCall) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">      const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> toolResult</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> this</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">callTool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(assistantResponse.toolCall) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 递归调用，将tool result作为新消息</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">      return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> this</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">chat</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(toolResult)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> assistantResponse.content</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>为了快速验证我的想法，我让 Claude Code 基于 Plasmo 快速开发了一个侧边栏形式的 Browser Agent，效果如下：</p><p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/068.png" alt="068" loading="lazy"></p><blockquote><p>这不是产品，只是 Demo。仅用于验证我自己所理解的 Loop。</p></blockquote><h2 id="我的感想" tabindex="-1">我的感想 <a class="header-anchor" href="#我的感想" aria-label="Permalink to &quot;我的感想&quot;">​</a></h2><p>在做完这些事情以后，我豁然开朗。</p><p>Agent 的“自动执行”，其核心就是这个 <strong>“LLM 思考 -&gt; 工具执行 -&gt; 结果反馈 -&gt; LLM 再思考”</strong> 的循环。</p><p>当然，我这个实现非常简陋。一个工业级的 Agent 框架（比如 LangChain）要复杂得多，它们需要处理：</p><ol><li><strong>LLM 兼容</strong>：如何适配不同厂商（OpenAI, Anthropic, Google）的接口和 <code>tool_call</code> 格式。</li><li><strong>工具管理</strong>：如何动态注册、描述和安全地执行工具。</li><li><strong>记忆（Memory）</strong>：如何在循环中管理越来越长的对话历史，防止 Token 溢出。</li><li><strong>路由（Router）</strong>：当有上百个工具时，如何决定调用哪一个。</li></ol><p>但通过亲自动手，我总算摸清了 ReAct 架构的基本原理。这对于我后续的学习，算是打下了一个很好的基础吧。</p><p>（完）</p>`,39)]))}const k=a(l,[["render",n]]);export{g as __pageData,k as default};
