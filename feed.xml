<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>CellStack - 工程师技术笔记</title>
        <link>https://stack.mcell.top</link>
        <description>计算机科学的工程实践和个人思考。涵盖前端开发、后端架构、DevOps运维、AI工程等技术领域的深度文章和实战经验分享。</description>
        <lastBuildDate>Sun, 02 Nov 2025 18:35:52 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>zh-cn</language>
        <copyright>© 2025 mCell</copyright>
        <item>
            <title><![CDATA[AI 专题]]></title>
            <link>https://stack.mcell.top/topics/ai/</link>
            <guid>https://stack.mcell.top/topics/ai/</guid>
            <pubDate>Sun, 02 Nov 2025 18:23:01 GMT</pubDate>
            <description><![CDATA[聚焦 AI 工程、Agent 架构、提示工程等主题文章。]]></description>
            <content:encoded><![CDATA[<h1 id="ai-专题" tabindex="-1">AI 专题 <a class="header-anchor" href="#ai-专题" aria-label="Permalink to &quot;AI 专题&quot;"></a></h1>
<p>软件开发正在经历范式转变，从编写确定性的代码，到编排不确定性的智能。</p>
<p>这个专题关注的是：如何将智能能力工程化。这不是训练模型，而是使用模型；不是研究算法，而是设计系统。核心挑战在于处理模型的不确定性、设计可靠的架构、在成本和效果之间找到平衡。</p>
<p>智能系统的开发需要新的思维方式：你不能像传统编程那样精确控制每一步，但也不能完全放任自流。你需要理解智能的边界，设计容错机制，用自然语言表达逻辑，让不同的智能模块协作完成复杂任务。</p>
<p>这是一个介于传统软件工程和机器学习之间的新领域——它需要工程师的系统思维，也需要对智能系统特性的深刻理解。</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[客户端专题]]></title>
            <link>https://stack.mcell.top/topics/client/</link>
            <guid>https://stack.mcell.top/topics/client/</guid>
            <pubDate>Sun, 02 Nov 2025 18:23:01 GMT</pubDate>
            <description><![CDATA[前端开发与客户端技术相关的文章集合。]]></description>
            <content:encoded><![CDATA[<h1 id="客户端专题" tabindex="-1">客户端专题 <a class="header-anchor" href="#客户端专题" aria-label="Permalink to &quot;客户端专题&quot;"></a></h1>
<p>前端开发的本质是在受限环境中创造流畅体验。</p>
<p>浏览器是一个复杂的运行时：单线程执行、异步事件驱动、多进程渲染、受限的存储和计算能力。这些约束不是障碍，而是设计的边界。理解这些边界，才能写出高性能、可靠的代码。</p>
<p>这个专题关注的是底层机制而非表层框架：为什么需要异步编程？如何突破单线程限制？数据如何在客户端持久化？动画为什么会掉帧？这些问题的答案不在文档里，而在对运行时环境的深刻理解中。</p>
<p>工程化不是使用工具，而是理解工具背后的原理。当你知道为什么某个技术方案有效，你就能在新场景中做出正确的决策。技术迭代很快，但底层原理是稳定的——这些知识的半衰期远比框架更长。</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[网络与运维专题]]></title>
            <link>https://stack.mcell.top/topics/netops/</link>
            <guid>https://stack.mcell.top/topics/netops/</guid>
            <pubDate>Sun, 02 Nov 2025 18:23:01 GMT</pubDate>
            <description><![CDATA[合并网络与系统运维相关的文章集合。]]></description>
            <content:encoded><![CDATA[<h1 id="网络与运维专题" tabindex="-1">网络与运维专题 <a class="header-anchor" href="#网络与运维专题" aria-label="Permalink to &quot;网络与运维专题&quot;"></a></h1>
<p>基础设施是应用的底座,工程效率是团队的倍增器。</p>
<p>现代软件开发早已打破了开发与运维的边界。容器化、自动化部署、持续集成、监控告警,这些不是&quot;别人的工作&quot;,而是工程能力的基本要求。一个不理解基础设施的开发者,很难写出真正可部署的代码;一个不熟悉系统环境的工程师,在排查线上问题时会举步维艰。</p>
<p>这个专题关注的是:缩短&quot;从代码到价值&quot;的路径。更快的构建、更可靠的部署、更及时的反馈——这需要理解自动化的边界、隔离的价值、配置的策略、监控的设计。</p>
<p>基础设施不是附属品,而是工程实践的核心部分。理解网络通信的本质、掌握系统环境的操作、设计高效的交付流程,这些能力决定了一个工程师能走多远。</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[服务端专题]]></title>
            <link>https://stack.mcell.top/topics/server/</link>
            <guid>https://stack.mcell.top/topics/server/</guid>
            <pubDate>Sun, 02 Nov 2025 18:23:01 GMT</pubDate>
            <description><![CDATA[服务端与后端工程相关的文章集合。]]></description>
            <content:encoded><![CDATA[<h1 id="服务端专题" tabindex="-1">服务端专题 <a class="header-anchor" href="#服务端专题" aria-label="Permalink to &quot;服务端专题&quot;"></a></h1>
<p>后端开发是在处理复杂性：并发、状态、一致性、可靠性。</p>
<p>服务端代码运行在看不见的地方，但它承载着系统的核心逻辑。一个请求的响应时间、一个查询的执行效率、一个锁的设计策略，这些细节决定了系统能否在高负载下稳定运行。</p>
<p>这个专题关注的是技术选择背后的权衡：什么时候需要并发？如何平衡同步和异步？状态应该放在哪里？一致性要牺牲什么？这些问题没有标准答案，只有在具体场景下的合理决策。</p>
<p>后端工程的核心不在于语言和框架，而在于对系统特性的理解。并发与并行、阻塞与非阻塞、有状态与无状态——这些是跨语言、跨框架的通用知识。理解它们，才能设计出可扩展、可维护、可观测的系统。</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Agent = LLM + Tools]]></title>
            <link>https://stack.mcell.top/topics/ai/agent_is_llm_plus_tools</link>
            <guid>https://stack.mcell.top/topics/ai/agent_is_llm_plus_tools</guid>
            <pubDate>Sun, 02 Nov 2025 18:08:08 GMT</pubDate>
            <description><![CDATA[深入浅出地讲解 AI Agent 的本质，从 LLM 到 Tools，从宿主环境到执行机制，用一个简洁的公式帮你理解 Claude Code、Codex 等智能体的工作原理。]]></description>
            <content:encoded><![CDATA[<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/064.png" alt="064.png" loading="lazy"></p>
<h1 id="agent-llm-tools" tabindex="-1">Agent = LLM + Tools <a class="header-anchor" href="#agent-llm-tools" aria-label="Permalink to &quot;Agent = LLM + Tools&quot;"></a></h1>
<p>最近，AI Agent 这个词非常火。</p>
<p>比如 Claude Code CLI、Codex，它能像个程序员一样，在你的命令行里读写文件、执行代码。很多人觉得很神奇，它到底是怎么做到的？</p>
<p>今天，我想谈谈我的理解。一句话就能概括。</p>
<h2 id="核心公式" tabindex="-1">核心公式 <a class="header-anchor" href="#核心公式" aria-label="Permalink to &quot;核心公式&quot;"></a></h2>
<p>我的观点是，AI Agent 的核心，就是下面这个公式：</p>
<p><strong>Agent = LLM + Tools</strong></p>
<p>Agent（智能体），等于 LLM（大语言模型），加上 Tools（工具）。</p>
<p>为什么这么说？我们来拆解一下。</p>
<h2 id="llm-思考的大脑" tabindex="-1">LLM：思考的大脑 <a class="header-anchor" href="#llm-思考的大脑" aria-label="Permalink to &quot;LLM：思考的大脑&quot;"></a></h2>
<p>LLM，比如 GPT-5 或 Claude 4.5，是 Agent 的“大脑”。</p>
<p>它非常聪明，擅长阅读、理解、思考、推理和做决策。你给它一个复杂的目标，它能帮你拆解成一步步的计划。</p>
<p>但是，LLM 本身有一个巨大的限制：<strong>它是一个封闭的“黑盒”</strong>。</p>
<p>它无法感知外部世界。你问它“我的桌面上有什么文件？”，它不知道。你让它“帮我把 A 文件的内容复制到 B 文件”，它也做不到。</p>
<p>它只能“想”，不能“做”。</p>
<h2 id="tools-连接世界的手脚" tabindex="-1">Tools：连接世界的手脚 <a class="header-anchor" href="#tools-连接世界的手脚" aria-label="Permalink to &quot;Tools：连接世界的手脚&quot;"></a></h2>
<p>要让 LLM “做”起来，就需要 Tools（工具）。</p>
<p>Tools，就是 Agent 的“手脚”和“感官”。它们是 LLM 连接外部世界的桥梁。</p>
<p>LLM 决定“做什么”（比如“读取 A 文件”），它不自己去读，而是去“调用”一个叫 <code>Read Tool</code> 的工具。这个工具负责真正执行操作，然后把结果（文件内容）返回给 LLM。</p>
<p>所以，常见的工具可能包括：</p>
<ul>
<li><code>Read Tool</code>：读取文件或网页内容。</li>
<li><code>Edit Tool</code>：修改或写入文件。</li>
<li><code>Delete Tool</code>：删除文件。</li>
<li><code>Find Tool</code>：搜索信息。</li>
<li><code>Execute Tool</code>：执行一段代码或命令。</li>
</ul>
<p>LLM 负责决策，Tools 负责执行。两者结合，Agent 就能感知和操作外部世界了。</p>
<h2 id="关键抽象-宿主环境" tabindex="-1">关键抽象：宿主环境 <a class="header-anchor" href="#关键抽象-宿主环境" aria-label="Permalink to &quot;关键抽象：宿主环境&quot;"></a></h2>
<p>Tools 到底是什么？</p>
<p>我们可以再抽象一点：<strong>Tools 是“宿主环境”能力的封装。</strong></p>
<p>这句话是关键。</p>
<ol>
<li>
<p>在 Claude Code CLI 这个例子里，“宿主环境”就是你的<strong>操作系统 (OS)</strong>。
Tools 封装的就是 <code>shell</code> 命令（比如 <code>ls</code>, <code>cat</code>, <code>sed</code>），让 LLM 能够操作你的本地文件。</p>
</li>
<li>
<p>如果我们想做一个“浏览器 Agent”呢？
“宿主环境”就是<strong>浏览器</strong>。
我们就需要封装浏览器提供的能力作为 Tools。</p>
</li>
</ol>
<h2 id="agent-的本质" tabindex="-1">Agent 的本质 <a class="header-anchor" href="#agent-的本质" aria-label="Permalink to &quot;Agent 的本质&quot;"></a></h2>
<p>所以，Agent 的创造逻辑就清晰了：</p>
<p>理论上，<strong>任何一个宿主环境，只要它提供的能力可以被封装成 Tools，我们就能基于它创造 Agent。</strong></p>
<ul>
<li>宿主环境是 OS，Agent 就是 OS 助手。</li>
<li>宿主环境是浏览器，Agent 就是浏览器助手。</li>
<li>宿主环境是数据库，Tools 就是 SQL 执行器，Agent 就是数据分析师。</li>
<li>宿主环境是 API 服务（比如天气、股票），Agent 就是你的生活助理。</li>
</ul>
<h2 id="不可或缺的-脚手架" tabindex="-1">不可或缺的“脚手架” <a class="header-anchor" href="#不可或缺的-脚手架" aria-label="Permalink to &quot;不可或缺的“脚手架”&quot;"></a></h2>
<p>当然，一个真正好用的 Agent，光有 <code>LLM + Tools</code> 还不够。</p>
<p>它还需要很多“脚手架”来支撑运转，比如：</p>
<ul>
<li><strong>上下文管理 (Context Management)</strong>：LLM 的“记忆”有限（即上下文窗口），如何只把最关键的信息喂给它？</li>
<li><strong>记忆 (Memory)</strong>：如何让 Agent 拥有短期记忆和长期记忆，从过去的经验中学习？</li>
<li><strong>执行机制 (Execution Mechanism)</strong>：如何设计一个循环（Loop），让“思考”和“行动”能交替往复、持续运行？（比如 ReAct 框架）</li>
<li><strong>提示词工程 (Prompt Engineering)</strong>：如何写好 Prompt，让 LLM 知道自己的目标、角色和手头有哪些工具可用？</li>
</ul>
<p>但万变不离其宗，这些机制都是为了让 <code>LLM + Tools</code> 这个核心公式更高效、更稳定地工作。</p>
<h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;"></a></h2>
<p><code>Agent = LLM + Tools</code>。</p>
<p>这个简洁的公式，为我们定义了一种新的软件范式。它告诉我们，如何将 LLM 的“智能”与现实世界的“能力”结合起来，创造出能自主感知和操作的智能体。</p>
<p>（完）</p>
]]></content:encoded>
            <enclosure url="https://stack-mcell.tos-cn-shanghai.volces.com/064.png" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[Agent ReAct and Loop]]></title>
            <link>https://stack.mcell.top/topics/ai/agent_react_and_loop</link>
            <guid>https://stack.mcell.top/topics/ai/agent_react_and_loop</guid>
            <pubDate>Sun, 02 Nov 2025 18:08:08 GMT</pubDate>
            <description><![CDATA[深入解析 AI Agent 的 ReAct 架构和工作循环原理，探讨智能体如何实现自动化任务执行，从理论到实践的完整指南。]]></description>
            <content:encoded><![CDATA[<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/065.png" alt="065.png" loading="lazy"></p>
<h1 id="agent-react-and-loop" tabindex="-1">Agent ReAct and Loop <a class="header-anchor" href="#agent-react-and-loop" aria-label="Permalink to &quot;Agent ReAct and Loop&quot;"></a></h1>
<p>我一直在使用 ChatGPT 或通义千问这样的 AI 工具，它们很强大，但多数情况下都是“一问一答”。我提一个问题，它给一个答案。</p>
<p>但我注意到，像 Manus 或 Claude Code CLI 这样的“Agent”（智能体）产品，它们似乎可以<strong>自动执行</strong>任务。你给它一个目标，它会自己去调用工具、分析结果、继续下一步，直到任务完成。</p>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/066.png" alt="066" loading="lazy"></p>
<p>这到底是怎么做到的？它如何摆脱“一问一答”的限制，实现自动循环？这就是我这周探索的问题。</p>
<h2 id="关键概念-react" tabindex="-1">关键概念：ReAct <a class="header-anchor" href="#关键概念-react" aria-label="Permalink to &quot;关键概念：ReAct&quot;"></a></h2>
<p>我读了一些资料，发现了一个关键概念：<strong>ReAct</strong>。</p>
<p>这是 2022 年一篇论文（<a href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noreferrer">ReAct: Synergizing Reasoning and Acting in Language Models</a>）提出的思想。它模仿了人类的工作方式：</p>
<ol>
<li><strong>Reason（思考）</strong>：分析当前情况，决定下一步该做什么。</li>
<li><strong>Act（行动）</strong>：执行一个动作（比如调用工具、搜索信息）。</li>
</ol>
<p>完成“行动”后，会得到一个新的“观察”（Observation），比如工具的返回结果。然后，Agent 带着这个新结果，回到第 1 步，再次“思考”，形成一个循环。</p>
<h2 id="一个线索-claude-的日志" tabindex="-1">一个线索：Claude 的日志 <a class="header-anchor" href="#一个线索-claude-的日志" aria-label="Permalink to &quot;一个线索：Claude 的日志&quot;"></a></h2>
<p>这个“思考-行动”的循环听起来很合理。为了验证它，我做了一个小实验。</p>
<p>我查看了 Claude 编码助手（我在 Mac 上的路径是 <code>./claude/projects/*.jsonl</code>）的会话日志文件。这些 <code>.jsonl</code> 文件记录了我和 Agent 的完整对话。</p>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/067.png" alt="067" loading="lazy"></p>
<p>我发现，里面的消息（Message）并不仅仅是“我问”和“它答”，而是主要有四种类型：</p>
<ul>
<li><code>user</code>：用户的消息。</li>
<li><code>assistant</code>：模型（Agent）的消息。</li>
<li><code>tool_call</code>：模型决定调用一个工具。</li>
<li><code>tool_result</code>：工具执行后返回的结果。</li>
</ul>
<p>这揭示了一个秘密：<code>assistant</code> 的回复并不总是最终答案。它可能是一个 <code>tool_call</code>（工具调用）请求，用来告诉外部程序：“请帮我执行这个函数”。</p>
<p>执行完毕后，系统会把 <code>tool_result</code>（工具结果）再发给 <code>assistant</code>。</p>
<h2 id="流程-一个循环" tabindex="-1">流程：一个循环 <a class="header-anchor" href="#流程-一个循环" aria-label="Permalink to &quot;流程：一个循环&quot;"></a></h2>
<p>看到这里，我基本想通了。Agent 的自动执行，本质上就是这样一个流程：</p>
<blockquote>
<p><code>[用户输入]</code> -&gt; <code>[LLM 思考]</code> -&gt; <code>[决定：调用工具 A]</code> -&gt; <code>[系统执行 A]</code> -&gt; <code>[A 的结果]</code> -&gt; <code>[LLM 思考]</code> -&gt; <code>[决定：调用工具 B]</code> -&gt; <code>[系统执行 B]</code> -&gt; ... -&gt; <code>[最终答案]</code></p>
</blockquote>
<p>这个流程的核心，就是一个<strong>循环（Loop）</strong>。</p>
<p>只要 LLM 返回的不是最终答案，而是一个 <code>tool_call</code>，系统就去执行它，然后把结果塞回去，让 LLM 继续“思考”。</p>
<h2 id="demo-快速验证" tabindex="-1">Demo 快速验证 <a class="header-anchor" href="#demo-快速验证" aria-label="Permalink to &quot;Demo 快速验证&quot;"></a></h2>
<p>我的逻辑很清晰：一个主函数，它负责调用 LLM。调用后，检查返回结果。</p>
<ul>
<li>如果结果是普通文本（最终答案），就返回它。</li>
<li>如果结果是 <code>tool_call</code>，就去执行工具，然后把工具结果和之前的对话历史“拼”在一起，<strong>递归调用</strong>自己。</li>
</ul>
<p>下面是一个简化的伪代码：</p>
<div class="language-javascript vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0"> SimpleAgent</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">  async</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0"> chat</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">message</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">    const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> assistantResponse</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> await</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> this</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">callLLM</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">(message)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> (assistantResponse.hasToolCall) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">      const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> toolResult</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> await</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> this</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">callTool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">(assistantResponse.toolCall) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D">// 递归调用，将tool result作为新消息</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">      return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> this</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">chat</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">(toolResult)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">    }</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> assistantResponse.content</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">}</span></span></code></pre>
</div><p>为了快速验证我的想法，我让 Claude Code 基于 Plasmo 快速开发了一个侧边栏形式的 Browser Agent，效果如下：</p>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/068.png" alt="068" loading="lazy"></p>
<blockquote>
<p>这不是产品，只是 Demo。仅用于验证我自己所理解的 Loop。</p>
</blockquote>
<h2 id="我的感想" tabindex="-1">我的感想 <a class="header-anchor" href="#我的感想" aria-label="Permalink to &quot;我的感想&quot;"></a></h2>
<p>在做完这些事情以后，我豁然开朗。</p>
<p>Agent 的“自动执行”，其核心就是这个 <strong>“LLM 思考 -&gt; 工具执行 -&gt; 结果反馈 -&gt; LLM 再思考”</strong> 的循环。</p>
<p>当然，我这个实现非常简陋。一个工业级的 Agent 框架（比如 LangChain）要复杂得多，它们需要处理：</p>
<ol>
<li><strong>LLM 兼容</strong>：如何适配不同厂商（OpenAI, Anthropic, Google）的接口和 <code>tool_call</code> 格式。</li>
<li><strong>工具管理</strong>：如何动态注册、描述和安全地执行工具。</li>
<li><strong>记忆（Memory）</strong>：如何在循环中管理越来越长的对话历史，防止 Token 溢出。</li>
<li><strong>路由（Router）</strong>：当有上百个工具时，如何决定调用哪一个。</li>
</ol>
<p>但通过亲自动手，我总算摸清了 ReAct 架构的基本原理。这对于我后续的学习，算是打下了一个很好的基础吧。</p>
<p>（完）</p>
]]></content:encoded>
            <enclosure url="https://stack-mcell.tos-cn-shanghai.volces.com/065.png" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[Claude Code Sub-agent 模式详解和实践]]></title>
            <link>https://stack.mcell.top/topics/ai/claude_code_sub_agent</link>
            <guid>https://stack.mcell.top/topics/ai/claude_code_sub_agent</guid>
            <pubDate>Sun, 02 Nov 2025 18:08:08 GMT</pubDate>
            <description><![CDATA[深入解析Claude Code的Sub-agent子代理模式，学会创建专业化AI代理来提升代码生成、数据分析等复杂任务的效率和准确性。附完整实践教程和最佳实践。]]></description>
            <content:encoded><![CDATA[<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/021.webp" alt="021.webp" loading="lazy"></p>
<h1 id="claude-code-sub-agent-模式的详解和实践" tabindex="-1">Claude Code Sub-agent 模式的详解和实践 <a class="header-anchor" href="#claude-code-sub-agent-模式的详解和实践" aria-label="Permalink to &quot;Claude Code Sub-agent 模式的详解和实践&quot;"></a></h1>
<blockquote>
<p>这篇文章是一个实践教程，读完后，你将学会如何在 Claude Code 环境中，创建和使用这些 AI 代理，从而显著提升代码生成、数据分析等复杂任务的效率和准确性。</p>
</blockquote>
<p>在上一篇关于《<a href="https://stack.mcell.top/blog/prompt_engineering_getting_started_engineering_ai" target="_blank" rel="noreferrer">提示工程（Prompt Engineering）入门指南</a>》的文章中，我们探讨了如何与一个大型语言模型（LLM）高效对话。核心思想是把 AI 看作一个无所不包的“通才”，通过巧妙的指令引导它完成任务。</p>
<p>这种方法在许多场景下都很有用。但当任务变得复杂时，比如需要结合多种专业知识时，你会发现，让一个“通才”面面俱到，其实非常困难。它的回答常常会变得宽泛、不精确，甚至出现事实错误。</p>
<p>今天，我向大家介绍一种更先进、也更高效的 AI 使用模式：<strong>Sub-agent（子代理）</strong>。</p>
<p>这个概念来自 Anthropic 的官方文档，但请注意，它特指 <strong>Claude Code 这个开发工具中的一项功能</strong>。</p>
<h2 id="为什么-通才-不够用" tabindex="-1">为什么“通才”不够用？ <a class="header-anchor" href="#为什么-通才-不够用" aria-label="Permalink to &quot;为什么“通才”不够用？&quot;"></a></h2>
<p>让我们从一个具体的场景开始。假设你正在开发一个数据分析应用，需要一个 AI 助手来帮助用户。用户的需求可能是：</p>
<blockquote>
<p>“请帮我从公司的 PostgreSQL 数据库中，提取过去三个月的销售数据，然后用 JavaScript 的 Echarts 库画一个条形图，并分析销售趋势。”</p>
</blockquote>
<p>如果你把这段话直接扔给一个通用的 LLM，会发生什么？</p>
<p>最好的情况是，它能理解你的意-图，并一次性生成 SQL 查询语句和 JavaScript 可视化代码。但更常见的情况是：</p>
<ul>
<li><strong>SQL 方言错误</strong>：它可能生成了适用于 MySQL 的 SQL，而不是 PostgreSQL。</li>
<li><strong>库的使用过时</strong>：它使用了 Echarts 的旧版 API。</li>
<li><strong>分析流于表面</strong>：趋势分析部分只是几句空话，没有深度。</li>
</ul>
<p>根本原因在于，这个任务横跨了三个专业领域：<strong>数据库查询 (SQL)、数据可视化 (Echarts) 和业务分析</strong>。指望一个模型在所有领域都达到专家级水平，是不现实的。</p>
<p>Sub-agent 模式就是为了解决这个问题。</p>
<h2 id="sub-agent-的工作流程" tabindex="-1">Sub-agent 的工作流程 <a class="header-anchor" href="#sub-agent-的工作流程" aria-label="Permalink to &quot;Sub-agent 的工作流程&quot;"></a></h2>
<p>在 Claude Code 环境中，Sub-agent 的本质是预先定义好的、拥有特定“人格”和“技能”的 AI 助手。</p>
<p>这个流程包含两个核心角色：</p>
<ol>
<li>
<p><strong>主 AI (Claude Code)</strong>：它就像一个总指挥。当你下达一个模糊的指令时，它会分析这个任务，并判断是否应该把它交给某个更专业的“手下”。</p>
</li>
<li>
<p><strong>子代理（Sub-agent）</strong>：这些是各个领域的专家，比如“代码审查员”、“数据库专家”等。它们有自己的系统提示、独立的上下文记忆、甚至被授权使用不同的工具（比如读写文件、执行 shell 命令）。当总指挥把任务交给它时，它会“启动”并专注地完成这一项工作。</p>
</li>
</ol>
<p>总的来说，就是 Claude Code 这个主 AI，可以智能地调用或委托任务给一个个预先配置好的、更专业的“分身”。</p>
<h2 id="sub-agent-实现方式" tabindex="-1">Sub-agent 实现方式 <a class="header-anchor" href="#sub-agent-实现方式" aria-label="Permalink to &quot;Sub-agent 实现方式&quot;"></a></h2>
<p>在 Claude Code 中创建和使用子代理非常直观，它依赖于配置文件，而不是复杂的代码。主要有两种方式。</p>
<h3 id="方式一-使用-agents-命令-推荐" tabindex="-1">方式一：使用 <code>/agents</code> 命令（推荐） <a class="header-anchor" href="#方式一-使用-agents-命令-推荐" aria-label="Permalink to &quot;方式一：使用 `/agents` 命令（推荐）&quot;"></a></h3>
<p>最简单的方式，是在 Claude Code 的交互界面中，输入斜杠命令：</p>
<div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">/agents</span></span></code></pre>
</div><p>这会弹出一个管理菜单，你可以根据引导，可视化地创建新的子代理，定义它的能力，并管理它可以使用的工具。对于新手来说，这是最不容易出错的方式。</p>
<h3 id="方式二-直接创建配置文件" tabindex="-1">方式二：直接创建配置文件 <a class="header-anchor" href="#方式二-直接创建配置文件" aria-label="Permalink to &quot;方式二：直接创建配置文件&quot;"></a></h3>
<p>子代理的本质，就是一个带有 YAML 头信息的 Markdown 文件。我们可以手动创建这些文件。</p>
<p>它们存放在两个地方：</p>
<ul>
<li><strong>项目级</strong>：<code>.claude/agents/</code> （仅在当前项目生效，优先级更高）</li>
<li><strong>用户级</strong>：<code>~/.claude/agents/</code> （在你的所有项目中都可用）</li>
</ul>
<p>一个子代理的配置文件结构如下：</p>
<div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">---</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">your-sub-agent-name</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">description</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">A natural language description of what this agent does and when it should be used.</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">tools</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">tool1, tool2</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D"> # 可选，允许该代理使用的工具</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">---</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">这里是这个子代理的系统提示（System Prompt）。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">你可以详细地描述它的角色、能力、行事风格和所有必须遵守的规则。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">写得越详细、越清晰，它被激活时表现得就越好。</span></span></code></pre>
</div><p>让我们以前文提到的“数据分析”任务为例，创建一个专门的 <code>echarts-expert</code> 子代理。</p>
<p>首先，在你的项目根目录下创建文件 <code>.claude/agents/echarts-expert.md</code>：</p>
<div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">mkdir</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> .claude/agents</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">touch</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> .claude/agents/echarts-expert.md</span></span></code></pre>
</div><p>然后，编辑这个文件，写入以下内容：</p>
<div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">---</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">echarts-expert</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">description</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">Echarts 可视化专家。当用户需要使用 JavaScript 和 Echarts 库创建图表时，应使用此代理。</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D">tools</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF">Read, Write</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">---</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">你是一位数据可视化专家，尤其精通 Apache Echarts 库。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">你的任务是：</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">1.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">  接收用户提供的数据或数据结构。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">2.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">  编写高质量、可直接运行的 Echarts JavaScript 代码。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">3.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">  确保代码遵循 Echarts 的最新最佳实践。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">4.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">  代码中必须包含清晰的注释，解释 </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`option`</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> 配置中的关键部分。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">5.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">  如果用户的数据不适合所选图表，要给出建议。</span></span></code></pre>
</div><p>这样，一个“Echarts 专家”就被创造出来了。同理，你还可以创建一个 <code>sql-expert</code>。</p>
<h3 id="如何使用子代理" tabindex="-1">如何使用子代理？ <a class="header-anchor" href="#如何使用子代理" aria-label="Permalink to &quot;如何使用子代理？&quot;"></a></h3>
<p>创建之后，有两种方式可以激活它：</p>
<ol>
<li>
<p><strong>自动委托</strong>：当你的指令和子代理的 <code>description</code> 字段高度匹配时，Claude Code 会自动调用它。比如，你直接说：“帮我用 Echarts 画个图”，它很可能就会激活我们刚刚创建的专家。</p>
</li>
<li>
<p><strong>显式调用</strong>：你也可以明确地“点名”，让某个专家来工作。</p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span>> 让 echarts-expert 帮我把我最近的销售数据做成一个饼图。</span></span></code></pre>
</div></li>
</ol>
<h2 id="sub-agent-模式的优势" tabindex="-1">Sub-agent 模式的优势 <a class="header-anchor" href="#sub-agent-模式的优势" aria-label="Permalink to &quot;Sub-agent 模式的优势&quot;"></a></h2>
<p>理解了正确的实现方式后，我们再来看它的优势，会更加清晰。这些优势是基于 Claude Code 这个工具环境的。</p>
<ol>
<li>
<p><strong>上下文保护</strong>：这是最重要的优势。每个子代理在自己<strong>独立</strong>的上下文窗口中运行。这意味着，调用一个“SQL 专家”去处理复杂的数据库查询时，不会污染你主对话窗口中关于前端代码的上下文。这让你可以进行非常长、非常复杂的项目对话，而不会因为上下文混乱导致 AI 表现下降。</p>
</li>
<li>
<p><strong>专业知识</strong>：你可以为每个子代理编写非常详细、非常有针对性的系统提示。一个“代码审查员”的提示，可以包含函数命名、错误处理、安全漏洞等几十条规则。这种“专才”的成功率，远高于让一个“通才”临时抱佛脚。</p>
</li>
<li>
<p><strong>可重用性</strong>：你定义好的用户级子代理（存放在 <code>~/.claude/agents/</code> 中），可以在你的所有项目中复用。你可以打造一套自己专属的、强大的“专家团队”，随时调用。</p>
</li>
<li>
<p><strong>灵活的权限管理 (Flexible Permissions)</strong>：你可以精细地控制每个子代理能使用的工具。比如，只有“测试工程师”这个子代理才有权限执行 <code>Bash</code> 命令去跑测试，而一个“文档撰写员”可能只能读取（<code>Read</code>）文件。这带来了更高的安全性。</p>
</li>
</ol>
<h2 id="结论" tabindex="-1">结论 <a class="header-anchor" href="#结论" aria-label="Permalink to &quot;结论&quot;"></a></h2>
<p>从“提示工程”到“代理工程”（Agent Engineering），我们正在从“与 AI 对话”进化到“设计和指挥 AI 系统”。</p>
<p>Claude Code 的 Sub-agent 功能，就是这种进化的一个极佳范例。从这个角度来看，未来的强大 AI 工具，可能不是一个无所不知的“神”，而是一个高度可配置、可扩展的平台。我们开发者可以通过编写简单的配置文件，就像组建团队一样，创建出无数“工匠”和“专家”，让它们在一个统一的环境下高效协作。</p>
<p>这种思维的转变至关重要：我们的工作不再仅仅是写代码或写提示词，更是设计、编排和优化这些 AI 代理，让它们成为我们开发流程中真正可靠的一环。</p>
<p><strong>（完）</strong></p>
]]></content:encoded>
            <enclosure url="https://stack-mcell.tos-cn-shanghai.volces.com/021.webp" length="0" type="image/webp"/>
        </item>
        <item>
            <title><![CDATA[长期以来我对 LLM 的误解]]></title>
            <link>https://stack.mcell.top/topics/ai/misunderstanding_llm</link>
            <guid>https://stack.mcell.top/topics/ai/misunderstanding_llm</guid>
            <pubDate>Sun, 02 Nov 2025 18:08:08 GMT</pubDate>
            <description><![CDATA[深入探讨大语言模型（LLM）的工作原理，理解从传统规则编程到概率计算的范式转换，揭秘模型参数与智能的本质。]]></description>
            <content:encoded><![CDATA[<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/051.png" alt="051.png" loading="lazy"></p>
<h1 id="长期以来我对-llm-的误解" tabindex="-1">长期以来我对 LLM 的误解 <a class="header-anchor" href="#长期以来我对-llm-的误解" aria-label="Permalink to &quot;长期以来我对 LLM 的误解&quot;"></a></h1>
<p>大家好，我是 mCell。</p>
<p>最近半年，我一直在折腾各种大语言模型（LLM），从 GPT 到 Gemini，再到国产的 DeepSeek、Qwen。我用它们当搜索引擎、写代码、甚至帮我完成期末作业的实验报告。作为一个开发者，我一直在思考一个问题：这东西的底层到底是怎么工作的？</p>
<h2 id="一个朴素的疑问" tabindex="-1">一个朴素的疑问 <a class="header-anchor" href="#一个朴素的疑问" aria-label="Permalink to &quot;一个朴素的疑问&quot;"></a></h2>
<p>我的疑问很简单：<strong>LLM 说到底只是一堆代码，它怎么就能“理解”我说的话呢？</strong></p>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/053.png" alt="053.png" loading="lazy"></p>
<p>按照我们传统程序员的思维，一个程序要实现特定功能，就需要明确的逻辑映射。比如，我们要写一个智能客服，代码可能是这样的：</p>
<div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0"> handle_query</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">(query):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">    if</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> "天气"</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">and</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> "今天"</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> query:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> get_todays_weather()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">    elif</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> "你好"</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">or</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> "早上好"</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583"> in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> query:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">        return</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> "你好！有什么可以帮你的吗？"</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">    else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583">        return</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> "抱歉，我听不懂你在说什么。"</span></span></code></pre>
</div><p>这种基于关键词和规则的方式，简单直接，但死板得像个石板。我们必须为每一种可能性预设好程序的分支。很多年前的手机助手，大抵就是这个逻辑。</p>
<p>但是，现在的 LLM 完全不同。我可以直接对它说“早上好”，它会像真人一样回复“早上好！今天又是元气满满的一天呢”，甚至可能还会根据上下文，附上一句“今天有什么安排吗？”。</p>
<p>我查看了那些开源模型的代码，并没有找到类似 <code>if query == &quot;早上好&quot;</code> 这样的特殊处理。谁说计算机没有黑魔法，这不就是魔法吗？</p>
<h2 id="ollama、7gb-文件和代码仓库" tabindex="-1">Ollama、7GB 文件和代码仓库 <a class="header-anchor" href="#ollama、7gb-文件和代码仓库" aria-label="Permalink to &quot;Ollama、7GB 文件和代码仓库&quot;"></a></h2>
<p>我最开始接触本地化运行大模型，是从 <code>ollama</code> 开始的。它的确非常方便，一条命令就能把模型跑起来：</p>
<div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> qwen:7b</span></span></code></pre>
</div><p>执行这条命令后，最让我印象深刻的是下载过程。一个 <code>qwen:7b</code> 模型，下载的文件体积动辄 7GB、14GB。</p>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/052.png" alt="052.png" loading="lazy"></p>
<p>这让我非常困惑。我去 GitHub 上看 Qwen 的<a href="https://github.com/QwenLM/Qwen" target="_blank" rel="noreferrer">官方仓库</a>，把整个项目克隆下来，所有 Python 代码加起来也不过几十 MB。</p>
<p><strong>7GB 的庞然大物，和几十 MB 的代码，这两者是什么关系？</strong></p>
<p>一开始我以为，它是不是像传统软件一样，附带了一个巨大的数据库？运行的时候，代码从这个数据库里检索信息？但这个猜测很快被我自己推翻了，我逐渐了解到 LLM 的回答是生成式的，而不是检索式的。它可以创造出全新的、数据库里根本不存在的句子。</p>
<p>很长一段时间，我都错误地认为那些代码本身通过某种我无法理解的复杂算法实现了“智能”。直到最近，我才恍然大悟：<strong>我一直忽略了模型真正的核心——参数。</strong></p>
<h2 id="被下载的不是-数据-而是-大脑" tabindex="-1">被下载的不是“数据”，而是“大脑” <a class="header-anchor" href="#被下载的不是-数据-而是-大脑" aria-label="Permalink to &quot;被下载的不是“数据”，而是“大脑”&quot;"></a></h2>
<p>现在我可以回答我自己的问题了。</p>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/054.png" alt="054.png" loading="lazy"></p>
<p>GitHub 上的代码，是 LLM 的 <strong>“骨架”<strong>或者说</strong>“引擎”</strong> 。它定义了一个叫做“Transformer”的神经网络结构，并规定了数据（也就是我们的文字）如何在其中流动和计算。它本身是“空”的，没有任何知识。</p>
<p>而我们通过 <code>ollama</code> 下载的那个 7GB 的文件，才是 LLM 的 <strong>“大脑”<strong>和</strong>“灵魂”</strong> 。它的官方名字叫做 <strong>模型参数（Parameters）<strong>或</strong>模型权重（Weights）</strong>。</p>
<p>这个文件里存储的是数十亿（7B 就是 70 亿）个经过训练优化的浮点数。这些数字，就是模型从数万亿单词的语料库中学习到的所有知识的浓缩和结晶。</p>
<p>这个学习过程被称为 <strong>“训练”</strong> 。你可以把它想象成一个极其复杂的拟合过程。模型看到“天空是”这句话，它被要求预测下一个词。它一开始会瞎猜，比如猜“绿色的”。然后我们告诉它，标准答案是“蓝色的”。它就会微调内部那 70 亿个参数，让自己下一次遇到类似情况时，猜出“蓝色的”概率高一点点。</p>
<p>这个过程重复数万亿次之后，模型内部的参数就形成了一种极其微妙的平衡。它不再是简单地记忆，而是学会了语法、逻辑、事实，甚至是某种程度上的“推理”能力。</p>
<p>所以，当我们输入“早上好”时，整个流程是这样的：</p>
<ol>
<li><strong>输入处理</strong>：推理代码（骨架）首先将“早上好”这三个汉字，通过一个叫做 Tokenizer 的工具，转换成一串数字 ID（比如 <code>[234, 567, 890]</code>）。</li>
<li><strong>矩阵运算</strong>：这串数字被输入到模型网络中，与那 7GB 文件里的 70 亿个参数进行一系列大规模的矩阵乘法运算。</li>
<li><strong>概率输出</strong>：运算的结果，是模型预测出的词汇表里每一个词在当前位置出现的概率。比如，“！”的概率可能是 30%，“今”的概率可能是 20%，“你”的概率可能是 15%……</li>
<li><strong>文本生成</strong>：代码根据这些概率，选择一个词（通常是概率最高的那个）作为输出，然后把这个新生成的词再作为新的输入，重复上述过程，直到生成完整的句子。</li>
</ol>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/055.png" alt="055.png" loading="lazy"></p>
<p>整个过程，没有一行 <code>if-else</code> 来判断用户意图，全都是冰冷的、确定性的数学计算。所谓的“智能”和“理解”，就蕴含在那 70 亿个参数构成的复杂函数之中。</p>
<h2 id="从规则到概率的飞跃" tabindex="-1">从规则到概率的飞跃 <a class="header-anchor" href="#从规则到概率的飞跃" aria-label="Permalink to &quot;从规则到概率的飞跃&quot;"></a></h2>
<p>想通了这一点，我有一种豁然开朗的感觉。</p>
<p>我们正处在一个范式转换的时代。传统的编程思维是<strong>基于规则的、确定性的</strong>。我们告诉计算机每一步该做什么。而 LLM 的思维是<strong>基于概率的、涌现性的</strong>。我们构建一个能够学习的框架，然后用海量数据“喂养”它，让“智能”从中自然“涌现”出来。</p>
<p>这或许就是为什么 LLM 能处理如此复杂和模糊的人类语言的原因。因为语言本身，在很多时候就不是一个严格的逻辑系统，而是一个充满了习惯、文化和上下文的概率系统。</p>
<p>所以，LLM 不是一个装满了数据的“超级数据库”，它是一个学会了语言规律的“概率计算引擎”。它的代码是骨架，而巨大的参数文件，才是它智慧的真正载体。</p>
<p><strong>参考链接：</strong></p>
<ol>
<li><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noreferrer">The Illustrated Transformer</a> (一篇非常经典的图解 Transformer 的文章)</li>
<li><a href="https://ollama.com/" target="_blank" rel="noreferrer">Ollama 官方网站</a></li>
<li><a href="https://github.com/QwenLM/Qwen" target="_blank" rel="noreferrer">Qwen (通义千问) GitHub 仓库</a></li>
</ol>
<p>(完)</p>
]]></content:encoded>
            <enclosure url="https://stack-mcell.tos-cn-shanghai.volces.com/051.png" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[提示工程（Prompt Engineering）入门指南 - 让AI懂你所想]]></title>
            <link>https://stack.mcell.top/topics/ai/prompt_engineering_getting_started</link>
            <guid>https://stack.mcell.top/topics/ai/prompt_engineering_getting_started</guid>
            <pubDate>Sun, 02 Nov 2025 18:08:08 GMT</pubDate>
            <description><![CDATA[基于Claude Code官方文档提炼的最实用提示工程技巧。从基础的清晰指令、提供范例，到进阶的思考链、角色设定，全面提升AI交互效果和工作效率。]]></description>
            <content:encoded><![CDATA[<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/020.jpg" alt="020.jpg" loading="lazy"></p>
<h1 id="提示工程-prompt-engineering-入门指南" tabindex="-1">提示工程（Prompt Engineering）入门指南 <a class="header-anchor" href="#提示工程-prompt-engineering-入门指南" aria-label="Permalink to &quot;提示工程（Prompt Engineering）入门指南&quot;"></a></h1>
<blockquote>
<p>这篇指南是我从 <a href="https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/overview" target="_blank" rel="noreferrer">Claude Code 官方文档</a> 中提炼出最核心的技巧，从基础的“清晰指令”和“提供范例”，到进阶的“思考链”和“角色设定”，帮助你将 AI 这个强大的工具，变成你工作流中不可或缺的伙伴。如果你想让 AI 真正懂你所想，这篇文章正是你需要的入门手册。</p>
</blockquote>
<p>最近一年，大语言模型（LLM）的发展，正在深刻地改变我们获取信息和创造内容的方式。无论是 Claude、GPT、Gemini 还是国内的各种模型，AI 已经成为许多人工作中不可或缺的伙伴。</p>
<p>但是，AI 的能力并非无限，它的表现好坏，直接取决于我们向它提出的问题和指令，也就是“提示词”（Prompt）。如何写出高质量的提示词，让 AI 更好地为我们服务？这就是“提示工程”（Prompt Engineering）这门新兴学问所研究的。</p>
<p>今天，我想系统地梳理一下 AI 公司 Anthropic（Claude 的开发者）官方文档里的一系列文章，将他们的最佳实践，总结成一份人人都能看懂的入门指南。</p>
<h2 id="基础原则-清晰、具体、有范例" tabindex="-1">基础原则：清晰、具体、有范例 <a class="header-anchor" href="#基础原则-清晰、具体、有范例" aria-label="Permalink to &quot;基础原则：清晰、具体、有范例&quot;"></a></h2>
<p>与 AI 沟通，最基本的要求就是清晰。你必须把它当成一个非常聪明、但极度缺乏背景知识、并且会严格按字面意思理解你话语的实习生。</p>
<h3 id="指令要直接明确" tabindex="-1">指令要直接明确 <a class="header-anchor" href="#指令要直接明确" aria-label="Permalink to &quot;指令要直接明确&quot;"></a></h3>
<p>避免使用模糊、口语化的表达。你需要明确告诉它“做什么”、“以什么格式”。</p>
<blockquote>
<p><strong>（不推荐）</strong></p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span>总结一下这篇文章。</span></span></code></pre>
</div><p><em>(点评：总结成多长？要点是什么？给谁看？AI 不得不猜测你的意图。)</em></p>
</blockquote>
<blockquote>
<p><strong>（推荐）</strong></p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span>请将以下文章总结成 5 个要点，每个要点不超过 30 个字，面向的读者是对这个领域不了解的初学者。</span></span>
<span class="line"><span>[此处附上文章内容]</span></span></code></pre>
</div></blockquote>
<h3 id="提供示例-few-shot-prompting" tabindex="-1">提供示例（Few-shot Prompting） <a class="header-anchor" href="#提供示例-few-shot-prompting" aria-label="Permalink to &quot;提供示例（Few-shot Prompting）&quot;"></a></h3>
<p>“Show, don't tell.”（展示，而非说教）。如果你需要 AI 完成特定格式或风格的任务，最好的方法就是给它一两个完整的范例。</p>
<blockquote>
<p><strong>（示例：提取 JSON 数据）</strong></p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span>从以下文本中提取关键信息，并以 JSON 格式输出。请参考下面的示例。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>&#x3C;example></span></span>
<span class="line"><span>文本: "张三的邮箱是 zhangsan@example.com，他的电话是 13800138000。"</span></span>
<span class="line"><span>JSON:</span></span>
<span class="line"><span>{</span></span>
<span class="line"><span>"name": "张三",</span></span>
<span class="line"><span>"email": "zhangsan@example.com",</span></span>
<span class="line"><span>"phone": "13800138000"</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span>&#x3C;/example></span></span>
<span class="line"><span></span></span>
<span class="line"><span>现在，请处理以下文本：</span></span>
<span class="line"><span></span></span>
<span class="line"><span>"李四的电话是 13900139000，邮箱是 lisi@example.com。"</span></span></code></pre>
</div><p>AI 会很轻松地学会这个模式，并输出正确的 JSON。</p>
</blockquote>
<h3 id="使用-xml-标签构建结构" tabindex="-1">使用 XML 标签构建结构 <a class="header-anchor" href="#使用-xml-标签构建结构" aria-label="Permalink to &quot;使用 XML 标签构建结构&quot;"></a></h3>
<p>当你的提示词包含多个部分（比如，背景信息、示例文档、具体问题、格式要求）时，使用 XML 标签可以极大地帮助 AI 理解结构，避免混淆。</p>
<blockquote>
<p><strong>（示例：分析报告）</strong></p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span>&#x3C;document></span></span>
<span class="line"><span>[这里放入一篇很长的分析报告...]</span></span>
<span class="line"><span>&#x3C;/document></span></span>
<span class="line"><span></span></span>
<span class="line"><span>&#x3C;instructions></span></span>
<span class="line"><span>你是一位资深的行业分析师。请阅读上面的 &#x3C;document>，并回答以下问题：</span></span>
<span class="line"><span></span></span>
<span class="line"><span>1. 这份报告的核心结论是什么？</span></span>
<span class="line"><span>2. 报告中提到的主要风险有哪些？</span></span>
<span class="line"><span>3. 报告作者的语气是乐观还是悲观？请用文中的例子说明。</span></span>
<span class="line"><span>&#x3C;/instructions></span></span></code></pre>
</div><p>这种结构化的输入，远比把所有文字混在一起要有效。</p>
</blockquote>
<h2 id="进阶技巧-引导-ai-思考" tabindex="-1">进阶技巧：引导 AI 思考 <a class="header-anchor" href="#进阶技巧-引导-ai-思考" aria-label="Permalink to &quot;进阶技巧：引导 AI 思考&quot;"></a></h2>
<p>对于复杂的、需要推理的任务，仅仅给出清晰的指令是不够的。我们还需要引导 AI 的“思考过程”。</p>
<h3 id="设定角色-system-prompts" tabindex="-1">设定角色（System Prompts） <a class="header-anchor" href="#设定角色-system-prompts" aria-label="Permalink to &quot;设定角色（System Prompts）&quot;"></a></h3>
<p>在所有指令的最前面，你可以设置一个“系统提示”（System Prompt）。它用来定义 AI 在整个对话中应该扮演的角色、遵循的规则和风格。这就像是为 AI 设置了“出厂默认值”。</p>
<blockquote>
<p><strong>（示例：技术文章写作助手）</strong></p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span>System: 你是一位专业的科技文章作者，你的写作风格简洁、严谨，擅长用类比来解释复杂的技术概念。在所有的回答中，请避免使用过于情绪化和口语化的词语。</span></span></code></pre>
</div><p>在这个 System Prompt 之后，你再提出的问题，AI 的回答都会遵循这个设定好的角色和风格。</p>
</blockquote>
<h3 id="任务分解与链式提示-chain-prompts" tabindex="-1">任务分解与链式提示（Chain Prompts） <a class="header-anchor" href="#任务分解与链式提示-chain-prompts" aria-label="Permalink to &quot;任务分解与链式提示（Chain Prompts）&quot;"></a></h3>
<p>不要指望 AI 一步到位地解决一个复杂问题。更可靠的方法是，将复杂任务分解成一系列更小的、连续的步骤，形成一个“提示链”。上一步的输出，可以作为下一步的输入。</p>
<blockquote>
<p><strong>（示例：市场分析报告流程）</strong></p>
<ol>
<li><strong>第一步（提取数据）</strong>：“请从这份财报中提取所有的关键财务指标，以 Markdown 表格形式呈现。”</li>
<li><strong>第二步（分析数据）</strong>：“根据上一步的表格，计算同比增长率和利润率，并分析其变化趋势。”</li>
<li><strong>第三步（生成摘要）</strong>：“综合以上分析，为公司 CEO 写一份不超过 200 字的摘要，重点说明公司的优势和潜在风险。”</li>
</ol>
</blockquote>
<h3 id="思考链-chain-of-thought" tabindex="-1">“思考链”（Chain of Thought） <a class="header-anchor" href="#思考链-chain-of-thought" aria-label="Permalink to &quot;“思考链”（Chain of Thought）&quot;"></a></h3>
<p>这是目前最强大的提示技巧之一。当你要求 AI 解决一个逻辑题或数学题时，不要直接让它给答案，而是<strong>要求它“一步步地思考”</strong>，并把思考过程写出来。</p>
<blockquote>
<p><strong>（示例：解决逻辑题）</strong></p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span>问题：一个篮子里有苹果和香蕉，总共 20 个水果。苹果的数量是香蕉的 3 倍。</span></span>
<span class="line"><span>请问苹果和香蕉各有多少个？</span></span>
<span class="line"><span>请不要直接给出答案。请先一步步地列出你的思考过程，最后再给出结论。</span></span></code></pre>
</div><p>AI 可能会这样回答：</p>
<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span></span></span>
<span class="line"><span>好的，让我一步步来思考这个问题。</span></span>
<span class="line"><span>第一步：定义变量。设香蕉的数量为 x。</span></span>
<span class="line"><span>第二步：根据题意，苹果的数量是香蕉的 3 倍，所以苹果的数量是 3x。</span></span>
<span class="line"><span>第三步：水果总数是 20，所以可以列出方程：x + 3x = 20。</span></span>
<span class="line"><span>第四步：解方程。4x = 20，所以 x = 5。</span></span>
<span class="line"><span>第五步：计算苹果的数量。苹果数量是 3x，所以是 3 \* 5 = 15。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>结论：因此，篮子里有 5 个香蕉和 15 个苹果。</span></span></code></pre>
</div><p>这个过程不仅让答案更可靠，也让我们能够检查它的逻辑是否正确。</p>
</blockquote>
<h2 id="特定场景-处理长文本" tabindex="-1">特定场景：处理长文本 <a class="header-anchor" href="#特定场景-处理长文本" aria-label="Permalink to &quot;特定场景：处理长文本&quot;"></a></h2>
<p>现代 AI 已经可以处理非常长的上下文（比如一整本书或一份几百页的文档）。但在处理长文本时，也有一些技巧。</p>
<ul>
<li><strong>指令后置</strong>：将你的具体问题或指令，放在长篇文档的<strong>末尾</strong>。因为模型通常对输入内容的开头和结尾最“敏感”。</li>
<li><strong>先提问，后填充</strong>：你可以先构造好你的问题框架，然后再把长篇文档插入。例如：<code>“根据下面的文档，请回答 XXX 问题。[文档内容]”</code>。</li>
<li><strong>引导性提问</strong>：不要只让 AI “总结文档”，而应该就文档内容提出具体、有针对性的问题，引导它去阅读和分析你最关心的部分。</li>
</ul>
<h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;"></a></h2>
<p>提示工程不是什么神秘的魔法，它是一门关于如何“清晰、结构化地表达自己意图”的学问。</p>
<p>回顾一下，核心要点包括：</p>
<ul>
<li><strong>基础</strong>：指令清晰、提供范例、使用标签。</li>
<li><strong>进阶</strong>：设定角色、分解任务、引导思考过程。</li>
<li><strong>长文本</strong>：指令后置、引导性提问。</li>
</ul>
<p>AI 是我们思想的“放大器”，而提示工程就是控制这个放大器的操作手册。掌握它，你就能让这个强大的工具，发挥出远超想象的威力。</p>
<h2 id="参考链接" tabindex="-1">参考链接 <a class="header-anchor" href="#参考链接" aria-label="Permalink to &quot;参考链接&quot;"></a></h2>
<ul>
<li><a href="https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering" target="_blank" rel="noreferrer">Anthropic, Prompt Engineering</a></li>
<li><a href="https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/system-prompts" target="_blank" rel="noreferrer">Anthropic, System Prompts</a></li>
<li><a href="https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/chain-of-thought" target="_blank" rel="noreferrer">Anthropic, Chain of Thought Prompting</a></li>
</ul>
<p>（完）</p>
]]></content:encoded>
            <enclosure url="https://stack-mcell.tos-cn-shanghai.volces.com/020.jpg" length="0" type="image/jpg"/>
        </item>
        <item>
            <title><![CDATA[Agents.md 是什么]]></title>
            <link>https://stack.mcell.top/topics/ai/what_is_agents_md</link>
            <guid>https://stack.mcell.top/topics/ai/what_is_agents_md</guid>
            <pubDate>Sun, 02 Nov 2025 18:08:08 GMT</pubDate>
            <description><![CDATA[深入解析 AGENTS.md 文件在 AI 编程工具生态中的作用，了解它与 MCP 协议的区别，以及如何为 AI 代理提供结构化项目上下文。]]></description>
            <content:encoded><![CDATA[<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/056.png" alt="056.png" loading="lazy"></p>
<h1 id="agents-md-又是什么" tabindex="-1">Agents.md 又是什么 <a class="header-anchor" href="#agents-md-又是什么" aria-label="Permalink to &quot;Agents.md 又是什么&quot;"></a></h1>
<p>最近，如果你关注 AI 编程工具的生态，可能会注意到两个新名词频繁出现：<strong>MCP</strong> 和 <strong>Agents.md</strong>。</p>
<p>MCP（Model Context Protocol）是为大语言模型（LLM）提供标准化上下文接入方式的协议，类似于让 LLM 能“看懂”外部工具、数据源和环境的一种通用语言。它试图解决的问题是：<strong>如何让不同的 AI 工具以统一方式向模型提供上下文？</strong></p>
<p>而 Agents.md，则看起来更“朴素”——它只是一个 Markdown 文件，放在你的代码仓库根目录下，内容通常是：</p>
<div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold">## Setup commands</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Install deps: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`pnpm install`</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Start dev server: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`pnpm dev`</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Run tests: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`pnpm test`</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold">## Code style</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> TypeScript strict mode</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Single quotes, no semicolons</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Use functional patterns where possible</span></span></code></pre>
</div><p>乍一看，这不就是 README 的一部分吗？为什么还要单独搞一个 <code>AGENTS.md</code>？</p>
<h2 id="人类看-readme-agent-看-agents-md" tabindex="-1">人类看 README，Agent 看 AGENTS.md <a class="header-anchor" href="#人类看-readme-agent-看-agents-md" aria-label="Permalink to &quot;人类看 README，Agent 看 AGENTS.md&quot;"></a></h2>
<p>关键区别在于<strong>受众不同</strong>。</p>
<ul>
<li><strong>README.md</strong> 是写给人看的：项目简介、快速上手、贡献指南、社区链接……它追求简洁、友好、有吸引力。</li>
<li><strong>AGENTS.md</strong> 是写给 AI 编程代理（coding agent）看的：构建命令、测试流程、代码风格、依赖结构、CI 规则……它追求<strong>精确、可执行、无歧义</strong>。</li>
</ul>
<p><img src="https://stack-mcell.tos-cn-shanghai.volces.com/057.png" alt="057.png" loading="lazy"></p>
<p>举个例子：人类看到“请先安装依赖”就懂了；但 AI 代理需要明确知道是 <code>npm install</code>、<code>yarn install</code> 还是 <code>pnpm install</code>。一个错字，整个自动化流程就可能崩掉。</p>
<p>所以，AGENTS.md 的出现，不是为了取代 README，而是<strong>为 AI 代理提供一个专属的、结构化的操作手册</strong>。</p>
<h2 id="为什么不能直接用-claude-md" tabindex="-1">为什么不能直接用 CLAUDE.md？ <a class="header-anchor" href="#为什么不能直接用-claude-md" aria-label="Permalink to &quot;为什么不能直接用 CLAUDE.md？&quot;"></a></h2>
<p>确实，像 Claude Code Cli 这样的工具已经支持通过 <code>CLAUDE.md</code> 提供项目上下文。但这带来一个问题：<strong>碎片化</strong>。</p>
<ul>
<li>Claude 用 <code>CLAUDE.md</code></li>
<li>Cursor 可能用 <code>.cursor/config.md</code></li>
<li>GitHub Copilot 实验性功能可能用 <code>.github/copilot.md</code></li>
<li>你自研的 agent 又定义了自己的格式……</li>
</ul>
<p>每个工具一套规则，开发者疲于维护多个“上下文文件”，而项目仓库也变得杂乱。</p>
<p><strong>AGENTS.md 的野心，是成为一个开放、通用、无厂商锁定的标准</strong>——就像 <code>package.json</code> 之于 Node.js，<code>.gitignore</code> 之于 Git。</p>
<p>它不隶属于 OpenAI、Anthropic 或 Google，而是由社区共建（包括 OpenAI Codex、Cursor、Google Jules 等团队参与推动）。目前已有超过 <a href="https://github.com/search?q=path%3AAGENTS.md&amp;type=code" target="_blank" rel="noreferrer">41,000</a> 个开源项目采用。</p>
<h2 id="agents-md-和-mcp-互补而非竞争" tabindex="-1">AGENTS.md 和 MCP：互补而非竞争 <a class="header-anchor" href="#agents-md-和-mcp-互补而非竞争" aria-label="Permalink to &quot;AGENTS.md 和 MCP：互补而非竞争&quot;"></a></h2>
<p>你可能会问：既然有了 MCP 这种“协议级”标准，还需要 AGENTS.md 这种“文件级”约定吗？</p>
<p>答案是：<strong>它们在不同层次工作，互为补充</strong>。</p>
<ul>
<li><strong>MCP</strong> 是运行时协议：定义 AI 如何与工具、API、数据库等<strong>动态交互</strong>。比如 Github 提交一个 PR。</li>
<li><strong>AGENTS.md</strong> 是静态上下文：告诉 AI “在这个项目里，你应该怎么做事”。比如“用 pnpm 而不是 npm”、“测试命令是 <code>pnpm test</code>”。</li>
</ul>
<p>可以这样类比：</p>
<ul>
<li>MCP 是“操作系统 API”，让程序能调用硬件；</li>
<li>AGENTS.md 是“项目 README for machines”，让 AI 能理解项目约定。</li>
</ul>
<p>一个管“能力接入”，一个管“行为规范”。</p>
<h2 id="写-agents-md-其实是在-教-ai-做人" tabindex="-1">写 AGENTS.md，其实是在“教 AI 做人” <a class="header-anchor" href="#写-agents-md-其实是在-教-ai-做人" aria-label="Permalink to &quot;写 AGENTS.md，其实是在“教 AI 做人”&quot;"></a></h2>
<p>AGENTS.md 的真正价值，不在于技术实现，而在于<strong>把隐性知识显性化</strong>。</p>
<p>很多项目中，构建流程、测试策略、代码风格其实只存在于老员工的脑子里，或者散落在 CI 配置、PR 模板、Slack 聊天记录里。新人（无论是人类还是 AI）进来都要“踩坑学习”。</p>
<p>而 AGENTS.md 强制你把这些规则写下来，形成一份<strong>可被机器理解的契约</strong>。</p>
<p>更妙的是，它还能嵌套：在 monorepo 中，每个子包都可以有自己的 <code>AGENTS.md</code>，实现上下文隔离。</p>
<h2 id="未来-ai-时代的-项目规范" tabindex="-1">未来：AI 时代的“项目规范” <a class="header-anchor" href="#未来-ai-时代的-项目规范" aria-label="Permalink to &quot;未来：AI 时代的“项目规范”&quot;"></a></h2>
<p>AGENTS.md 的愿景，是成为每个代码仓库的“标配文件”——就像 LICENSE、README、package.json 一样自然。</p>
<p>它不炫技，不复杂，只是一个简单的 Markdown 文件。但正是这种简单，让它有可能被广泛采纳。</p>
<h2 id="结语" tabindex="-1">结语 <a class="header-anchor" href="#结语" aria-label="Permalink to &quot;结语&quot;"></a></h2>
<p>技术演进常常如此：先有混乱的实践，再有统一的规范。</p>
<p>MCP 解决了“AI 如何连接世界”的问题，<br>
AGENTS.md 则解决“AI 如何理解你的项目”的问题。</p>
<p>一个向外连接，一个向内约定。</p>
<p>当这两个方向都逐渐标准化，AI 编程代理才能真正从“玩具工程”变成“生产力工具”。</p>
<p>而作为开发者，我们能做的，就是在你的下一个有 AI 参与开发的项目里，加一个 <code>AGENTS.md</code>。</p>
<p>不需要多复杂，只要写清楚三件事：</p>
<ol>
<li>怎么跑起来？</li>
<li>怎么测正确？</li>
<li>代码怎么写？</li>
</ol>
<p>这就够了。</p>
<blockquote>
<p><strong>附：AGENTS.md 示例模板</strong></p>
<div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0" v-pre=""><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold"># AGENTS.md</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold">## Setup</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Install: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`pnpm install`</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Dev: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`pnpm dev`</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold">## Testing</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Run all tests: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`pnpm test`</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Lint: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">`pnpm lint`</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold">## Code Style</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> TypeScript with strict mode</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Single quotes, no semicolons</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8"> Prefer functional over class-based components</span></span></code></pre>
</div></blockquote>
<p>（完）</p>
]]></content:encoded>
            <enclosure url="https://stack-mcell.tos-cn-shanghai.volces.com/056.png" length="0" type="image/png"/>
        </item>
    </channel>
</rss>