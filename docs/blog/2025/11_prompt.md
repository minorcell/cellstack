---
title: 提示工程（Prompt Engineering）入门指南 - 让AI懂你所想
description: 基于Claude Code官方文档提炼的最实用提示工程技巧。从基础的清晰指令、提供范例，到进阶的思考链、角色设定，全面提升AI交互效果和工作效率。
tags:
  - 提示工程
  - Prompt Engineering
  - Claude Code
  - AI交互
  - 人工智能
  - 大语言模型
  - LLM
  - 思考链
  - 角色设定
  - AI工具
  - 效率提升
  - 实用技巧
author: mCell
---

![020.jpg](https://stack-mcell.tos-cn-shanghai.volces.com/020.jpg)

# 提示工程（Prompt Engineering）入门指南

> 这篇指南是我从 [Claude Code 官方文档](https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/overview) 中提炼出最核心的技巧，从基础的“清晰指令”和“提供范例”，到进阶的“思考链”和“角色设定”，帮助你将 AI 这个强大的工具，变成你工作流中不可或缺的伙伴。如果你想让 AI 真正懂你所想，这篇文章正是你需要的入门手册。

最近一年，大语言模型（LLM）的发展，正在深刻地改变我们获取信息和创造内容的方式。无论是 Claude、GPT、Gemini 还是国内的各种模型，AI 已经成为许多人工作中不可或缺的伙伴。

但是，AI 的能力并非无限，它的表现好坏，直接取决于我们向它提出的问题和指令，也就是“提示词”（Prompt）。如何写出高质量的提示词，让 AI 更好地为我们服务？这就是“提示工程”（Prompt Engineering）这门新兴学问所研究的。

今天，我想系统地梳理一下 AI 公司 Anthropic（Claude 的开发者）官方文档里的一系列文章，将他们的最佳实践，总结成一份人人都能看懂的入门指南。

## 一、基础原则：清晰、具体、有范例

与 AI 沟通，最基本的要求就是清晰。你必须把它当成一个非常聪明、但极度缺乏背景知识、并且会严格按字面意思理解你话语的实习生。

### 1.1 指令要直接明确

避免使用模糊、口语化的表达。你需要明确告诉它“做什么”、“以什么格式”。

> **（不推荐）**
>
> ```
> 总结一下这篇文章。
> ```
>
> _(点评：总结成多长？要点是什么？给谁看？AI 不得不猜测你的意图。)_

> **（推荐）**
>
> ```
> 请将以下文章总结成 5 个要点，每个要点不超过 30 个字，面向的读者是对这个领域不了解的初学者。
> [此处附上文章内容]
> ```

### 1.2 提供示例（Few-shot Prompting）

“Show, don't tell.”（展示，而非说教）。如果你需要 AI 完成特定格式或风格的任务，最好的方法就是给它一两个完整的范例。

> **（示例：提取 JSON 数据）**
>
> ```
> 从以下文本中提取关键信息，并以 JSON 格式输出。请参考下面的示例。
>
> <example>
> 文本: "张三的邮箱是 zhangsan@example.com，他的电话是 13800138000。"
> JSON:
> {
> "name": "张三",
> "email": "zhangsan@example.com",
> "phone": "13800138000"
> }
> </example>
>
> 现在，请处理以下文本：
>
> "李四的电话是 13900139000，邮箱是 lisi@example.com。"
> ```
>
> AI 会很轻松地学会这个模式，并输出正确的 JSON。

### 1.3 使用 XML 标签构建结构

当你的提示词包含多个部分（比如，背景信息、示例文档、具体问题、格式要求）时，使用 XML 标签可以极大地帮助 AI 理解结构，避免混淆。

> **（示例：分析报告）**
>
> ```
> <document>
> [这里放入一篇很长的分析报告...]
> </document>
>
> <instructions>
> 你是一位资深的行业分析师。请阅读上面的 <document>，并回答以下问题：
>
> 1. 这份报告的核心结论是什么？
> 2. 报告中提到的主要风险有哪些？
> 3. 报告作者的语气是乐观还是悲观？请用文中的例子说明。
> </instructions>
> ```
>
> 这种结构化的输入，远比把所有文字混在一起要有效。

## 二、进阶技巧：引导 AI 思考

对于复杂的、需要推理的任务，仅仅给出清晰的指令是不够的。我们还需要引导 AI 的“思考过程”。

### 2.1 设定角色（System Prompts）

在所有指令的最前面，你可以设置一个“系统提示”（System Prompt）。它用来定义 AI 在整个对话中应该扮演的角色、遵循的规则和风格。这就像是为 AI 设置了“出厂默认值”。

> **（示例：技术文章写作助手）**
>
> ```
> System: 你是一位专业的科技文章作者，你的写作风格简洁、严谨，擅长用类比来解释复杂的技术概念。在所有的回答中，请避免使用过于情绪化和口语化的词语。
> ```
>
> 在这个 System Prompt 之后，你再提出的问题，AI 的回答都会遵循这个设定好的角色和风格。

### 2.2 任务分解与链式提示（Chain Prompts）

不要指望 AI 一步到位地解决一个复杂问题。更可靠的方法是，将复杂任务分解成一系列更小的、连续的步骤，形成一个“提示链”。上一步的输出，可以作为下一步的输入。

> **（示例：市场分析报告流程）**
>
> 1.  **第一步（提取数据）**：“请从这份财报中提取所有的关键财务指标，以 Markdown 表格形式呈现。”
> 2.  **第二步（分析数据）**：“根据上一步的表格，计算同比增长率和利润率，并分析其变化趋势。”
> 3.  **第三步（生成摘要）**：“综合以上分析，为公司 CEO 写一份不超过 200 字的摘要，重点说明公司的优势和潜在风险。”

### 2.3 “思考链”（Chain of Thought）

这是目前最强大的提示技巧之一。当你要求 AI 解决一个逻辑题或数学题时，不要直接让它给答案，而是**要求它“一步步地思考”**，并把思考过程写出来。

> **（示例：解决逻辑题）**
>
> ```
> 问题：一个篮子里有苹果和香蕉，总共 20 个水果。苹果的数量是香蕉的 3 倍。
> 请问苹果和香蕉各有多少个？
> 请不要直接给出答案。请先一步步地列出你的思考过程，最后再给出结论。
> ```
>
> AI 可能会这样回答：
>
> ```
>
> 好的，让我一步步来思考这个问题。
> 第一步：定义变量。设香蕉的数量为 x。
> 第二步：根据题意，苹果的数量是香蕉的 3 倍，所以苹果的数量是 3x。
> 第三步：水果总数是 20，所以可以列出方程：x + 3x = 20。
> 第四步：解方程。4x = 20，所以 x = 5。
> 第五步：计算苹果的数量。苹果数量是 3x，所以是 3 \* 5 = 15。
>
> 结论：因此，篮子里有 5 个香蕉和 15 个苹果。
> ```
>
> 这个过程不仅让答案更可靠，也让我们能够检查它的逻辑是否正确。

## 三、特定场景：处理长文本

现代 AI 已经可以处理非常长的上下文（比如一整本书或一份几百页的文档）。但在处理长文本时，也有一些技巧。

- **指令后置**：将你的具体问题或指令，放在长篇文档的**末尾**。因为模型通常对输入内容的开头和结尾最“敏感”。
- **先提问，后填充**：你可以先构造好你的问题框架，然后再把长篇文档插入。例如：`“根据下面的文档，请回答 XXX 问题。[文档内容]”`。
- **引导性提问**：不要只让 AI “总结文档”，而应该就文档内容提出具体、有针对性的问题，引导它去阅读和分析你最关心的部分。

## 总结

提示工程不是什么神秘的魔法，它是一门关于如何“清晰、结构化地表达自己意图”的学问。

回顾一下，核心要点包括：

- **基础**：指令清晰、提供范例、使用标签。
- **进阶**：设定角色、分解任务、引导思考过程。
- **长文本**：指令后置、引导性提问。

AI 是我们思想的“放大器”，而提示工程就是控制这个放大器的操作手册。掌握它，你就能让这个强大的工具，发挥出远超想象的威力。

## 参考链接

- [Anthropic, Prompt Engineering](https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering)
- [Anthropic, System Prompts](https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/system-prompts)
- [Anthropic, Chain of Thought Prompting](https://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/chain-of-thought)

（完）
